import ollama
import time
from pathlib import Path
import json
from tqdm import tqdm


class ModelTrainer:
    def __init__(self, base_model: str, data_path: str, output_name: str):
        self.base_model = base_model
        self.data_path = data_path
        self.output_name = output_name
        self.validation_split = 0.15  # 15%æ•°æ®ç”¨äºéªŒè¯

    def _prepare_dataset(self) -> str:
        """å°†æ•°æ®é›†è½¬æ¢ä¸ºOllamaè¦æ±‚çš„èŠå¤©æ ¼å¼"""
        # è¯»å–å¹¶é¢„å¤„ç†å®Œæ•´æ•°æ®é›†
        with open(self.data_path, 'r', encoding='utf-8') as f:
            samples = [line.strip() for line in f if line.strip()]

        # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
        split_idx = int(len(samples) * (1 - self.validation_split))
        train_data = samples[:split_idx]
        val_data = samples[split_idx:]

        # è½¬æ¢ä¸ºOllamaæ ¼å¼[4](@ref)
        def format_chat(sample):
            return {
                "messages": [
                    {"role": "user", "content": sample.split('|')[0]},
                    {"role": "assistant", "content": sample.split('|')[1]}
                ]
            }

        # ä¿å­˜è®­ç»ƒé›†
        train_path = f"{self.output_name}_train.jsonl"
        with open(train_path, 'w') as f:
            for sample in train_data:
                f.write(json.dumps(format_chat(sample)) + '\n')

        # ä¿å­˜éªŒè¯é›†
        val_path = f"{self.output_name}_val.jsonl"
        with open(val_path, 'w') as f:
            for sample in val_data:
                f.write(json.dumps(format_chat(sample)) + '\n')

        return train_path, val_path

    def _create_modelfile(self, train_path: str) -> str:
        """ç”ŸæˆåŒ…å«å®Œæ•´è®­ç»ƒå‚æ•°çš„Modelfile"""
        modelfile_content = f"""
FROM {self.base_model}
SYSTEM "æ‚¨æ˜¯ä¸€ä¸ªé¢†åŸŸä¸“å®¶åŠ©æ‰‹"
PARAMETER num_epochs 5
PARAMETER learning_rate 0.0002
PARAMETER num_ctx 4096
TEMPLATE """
        # æ·»åŠ å®Œæ•´è®­ç»ƒæ•°æ®å¼•ç”¨
        modelfile_content += f"\"\"\"{Path(train_path).read_text(encoding='utf-8')}\"\"\"\n"

        modelfile_path = f"{self.output_name}.Modelfile"
        with open(modelfile_path, 'w', encoding='utf-8') as f:
            f.write(modelfile_content)

        return modelfile_path

    def _monitor_training(self, job_id: str):
        """å®æ—¶ç›‘æ§è®­ç»ƒè¿›åº¦"""
        print(f"ğŸš€ è®­ç»ƒå·²å¯åŠ¨ | ä»»åŠ¡ID: {job_id}")
        progress_bar = tqdm(total=100, desc="è®­ç»ƒè¿›åº¦")
        prev_progress = 0

        while True:
            status = ollama.show(job_id)
            current = status.get('progress', 0)

            # æ›´æ–°è¿›åº¦æ¡
            if current > prev_progress:
                progress_bar.update(current - prev_progress)
                prev_progress = current

            # å®Œæˆæ£€æµ‹
            if status.get('status') == 'completed':
                progress_bar.close()
                print(f"âœ… è®­ç»ƒå®Œæˆ! å³°å€¼å‡†ç¡®ç‡: {status['metrics']['accuracy']:.2%}")
                return

            # é”™è¯¯å¤„ç†
            if status.get('status') == 'failed':
                progress_bar.close()
                print(f"âŒ è®­ç»ƒå¤±è´¥: {status['error']}")
                exit(1)

            time.sleep(5)

    def fine_tune(self):
        """æ‰§è¡Œç«¯åˆ°ç«¯å¾®è°ƒæµç¨‹"""
        # 1. æ•°æ®é¢„å¤„ç†
        train_path, val_path = self._prepare_dataset()
        print(
            f"ğŸ“Š æ•°æ®é›†åŠ è½½å®Œæˆ | è®­ç»ƒæ ·æœ¬: {Path(train_path).read_text().count('')} | éªŒè¯æ ·æœ¬: {Path(val_path).read_text().count('')}")

        # 2. åˆ›å»ºè®­ç»ƒé…ç½®
        modelfile_path = self._create_modelfile(train_path)
        print(f"âš™ï¸ ç”ŸæˆModelfile: {modelfile_path}")

        # 3. å¯åŠ¨è®­ç»ƒä»»åŠ¡
        job = ollama.create(
            name=self.output_name,
            modelfile=modelfile_path,
            stream=False
        )

        # 4. ç›‘æ§è®­ç»ƒè¿‡ç¨‹
        self._monitor_training(job['id'])

        # 5. æ¨¡å‹éªŒè¯
        val_results = ollama.evaluate(
            model=self.output_name,
            dataset=val_path,
            metrics=['perplexity', 'accuracy']
        )
        print(f"ğŸ§ª éªŒè¯ç»“æœ: å›°æƒ‘åº¦={val_results['perplexity']:.2f} | å‡†ç¡®ç‡={val_results['accuracy']:.2%}")

        return {
            "model": self.output_name,
            "val_metrics": val_results
        }


if __name__ == "__main__":
    trainer = ModelTrainer(
        base_model="llama3",
        data_path="finance_qa.txt",  # æ ¼å¼: é—®é¢˜|ç­”æ¡ˆ
        output_name="finance-expert-v1"
    )

    result = trainer.fine_tune()
    print(f"\nğŸ¦™ æ–°æ¨¡å‹ '{result['model']}' å·²éƒ¨ç½²!")
    print("ğŸ’¡ åœ¨model.pyä¸­é€‰æ‹©æ­¤æ¨¡å‹è¿›è¡Œå¯¹è¯æµ‹è¯•")